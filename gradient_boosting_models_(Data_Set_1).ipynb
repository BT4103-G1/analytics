{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradient_boosting models (Data Set 1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPyRlQ-qn2nn"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/train_FD001.txt',sep=\" \",header=None)\n",
        "test = pd.read_csv('/content/test_FD001.txt',sep=\" \",header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw5Pv2PFoVso"
      },
      "source": [
        "# renaming columns\n",
        "## used \"s<sensor_number>\" for simplicity\n",
        "columns = ['unit_number','time_in_cycles','setting_1','setting_2','setting_3','s1','s2','s3','s4','s5','s6','s7','s8',\n",
        "           's9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21', '26', '27' ]\n",
        "train.columns = columns\n",
        "test.columns = columns\n",
        "# since the last 2 columns do not contain any (useful) values (all null values), drop the columns\n",
        "train = train.drop(['26', '27'], axis = 1)\n",
        "test = test.drop(['26', '27'], axis = 1)\n",
        "# calculating RUL\n",
        "rul = pd.DataFrame(train.groupby('unit_number')['time_in_cycles'].max()).reset_index()\n",
        "rul.columns = ['unit_number', 'max']\n",
        "train = train.merge(rul, on=['unit_number'], how='left')\n",
        "train['RUL'] = train['max'] - train['time_in_cycles']\n",
        "train.drop('max', axis=1, inplace=True)\n",
        "to_drop = ['s1', 's5', 's10', 's16', 's18', 's19', 'setting_3', 'unit_number']\n",
        "X_train = train.drop(to_drop, axis = 1)\n",
        "y_train = X_train.pop('RUL')\n",
        "X_test = test.groupby('unit_number').last().reset_index().drop(to_drop, axis=1)\n",
        "test2 = test.groupby('unit_number').last().reset_index()\n",
        "\n",
        "## \n",
        "# import true RUL of test data\n",
        "y_true = pd.read_csv('/content/RUL_FD001.txt',delim_whitespace=True,names=[\"RUL\"])\n",
        "y_true[\"unit_number\"] = y_true.index\n",
        "y_true_new = [true[0] for true in y_true.values.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-DYs0YGodQY"
      },
      "source": [
        "# import true RUL of test data\n",
        "y_true = pd.read_csv('/content/RUL_FD001.txt',delim_whitespace=True,names=[\"RUL\"])\n",
        "y_true[\"unit_number\"] = y_true.index\n",
        "y_true_new = [true[0] for true in y_true.values.tolist()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rroOrvbT_fgo"
      },
      "source": [
        "## Grid Search with XGBoostRegressor ***\n",
        "- RMSE: 25.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECw5mAEA9BPp",
        "outputId": "37ec10d0-6655-4ccc-fb51-98bdb65ab8f7"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import preprocessing\n",
        "rf = XGBRFRegressor(n_estimators=300, subsample=0.9, colsample_bynode=0.2, n_fold = 5, eval_metric = 'rmse')\n",
        "# set up 5-fold cross-validation\n",
        "from sklearn import model_selection\n",
        "cv = model_selection.KFold(5)\n",
        "# pipeline standardization and model\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler())\n",
        "                           , ('model', rf) ])\n",
        "# tune the model\n",
        "my_min_samples_leaf = [2, 10, 25, 50, 100]\n",
        "my_max_depth = [7, 8, 9, 10, 11, 12]\n",
        "# run the model using gridsearch, select the model with best search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "optimized_rf = GridSearchCV(estimator=pipeline\n",
        "                            , cv=cv\n",
        "                            , param_grid =dict(model__min_samples_leaf = my_min_samples_leaf, model__max_depth = my_max_depth)\n",
        "                            , scoring = 'neg_mean_squared_error'\n",
        "                            , verbose = 1\n",
        "                            , n_jobs = -1\n",
        "                           )\n",
        "optimized_rf.fit(X_train, y_train)\n",
        "# show the best model estimators\n",
        "print(optimized_rf.best_estimator_)\n",
        "# evaluate metrics on holdout\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "y_pred = optimized_rf.predict(X_test)\n",
        "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_true_new, y_pred))\n",
        "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_true_new, y_pred))\n",
        "print(\"Random Forest r-squared: \", r2_score(y_true_new, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  8.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[12:49:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Pipeline(memory=None,\n",
            "         steps=[('standardize',\n",
            "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
            "                ('model',\n",
            "                 XGBRFRegressor(base_score=0.5, colsample_bylevel=1,\n",
            "                                colsample_bynode=0.2, colsample_bytree=1,\n",
            "                                eval_metric='rmse', gamma=0, learning_rate=1,\n",
            "                                max_delta_step=0, max_depth=12,\n",
            "                                min_child_weight=1, min_samples_leaf=2,\n",
            "                                missing=None, n_estimators=300, n_fold=5,\n",
            "                                n_jobs=1, nthread=None, objective='reg:linear',\n",
            "                                random_state=0, reg_alpha=0, reg_lambda=1,\n",
            "                                scale_pos_weight=1, seed=None, silent=None,\n",
            "                                subsample=0.9, verbosity=1))],\n",
            "         verbose=False)\n",
            "Random Forest Mean Squared Error:  629.4551136839975\n",
            "Random Forest Mean Absolute Error:  18.85700249671936\n",
            "Random Forest r-squared:  0.6354935464241205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5ljjQyvc8AW"
      },
      "source": [
        "## Standard Scaler with XGBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ1BgqDwpqMQ",
        "outputId": "115be44e-f71e-470a-93d9-a4ce2c8a391b"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_new = scaler.fit_transform(X_train)\n",
        "X_test_new = scaler.transform(X_test)\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRFRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "model = XGBRFRegressor(n_estimators=300, subsample=0.9, colsample_bynode=0.2, n_fold = 5, eval_metric = 'rmse')\n",
        "model.fit(X_train_new, y_train)\n",
        "y_pred = model.predict(X_test_new)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_true_new, y_pred))\n",
        "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_true_new, y_pred))\n",
        "print(\"Random Forest r-squared: \", r2_score(y_true_new, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[08:34:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Random Forest Mean Squared Error:  705.6391298488867\n",
            "Random Forest Mean Absolute Error:  21.749595603942872\n",
            "Random Forest r-squared:  0.5913767143454915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6DhVAF19NCq"
      },
      "source": [
        "- scaling does not matter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1owhxC5b9C0s",
        "outputId": "2b4fdde7-78cc-4357-9fa9-5a66f1f50453"
      },
      "source": [
        "X_train_new = X_train\n",
        "X_test_new = X_test\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRFRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "model = XGBRFRegressor(n_estimators=300, subsample=0.9, colsample_bynode=0.2, n_fold = 5, eval_metric = 'rmse')\n",
        "model.fit(X_train_new, y_train)\n",
        "y_pred = model.predict(X_test_new)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_true_new, y_pred))\n",
        "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_true_new, y_pred))\n",
        "print(\"Random Forest r-squared: \", r2_score(y_true_new, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12:39:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Random Forest Mean Squared Error:  705.6391298488867\n",
            "Random Forest Mean Absolute Error:  21.749595603942872\n",
            "Random Forest r-squared:  0.5913767143454915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJEDhif_XIKh"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "# A parameter grid for XGBoost\n",
        "params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
        "'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}\n",
        "xgb = XGBRegressor(nthread=-1) \n",
        "grid = GridSearchCV(xgb, params)\n",
        "grid.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_true_new, y_pred))\n",
        "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_true_new, y_pred))\n",
        "print(\"Random Forest r-squared: \", r2_score(y_true_new, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9BXUJLXdCYe"
      },
      "source": [
        "## LGBMRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-rvhc9PuPpZ",
        "outputId": "f248e4ff-0dc5-4887-f8b8-dbc210207699"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMRegressor\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_new = scaler.fit_transform(X_train)\n",
        "X_test_new = scaler.transform(X_test)\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRFRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "model = LGBMRegressor()\n",
        "model.fit(X_train_new, y_train)\n",
        "y_pred = model.predict(X_test_new)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_true_new, y_pred))\n",
        "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_true_new, y_pred))\n",
        "print(\"Random Forest r-squared: \", r2_score(y_true_new, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Mean Squared Error:  734.2606515752113\n",
            "Random Forest Mean Absolute Error:  19.410116322234938\n",
            "Random Forest r-squared:  0.5748024914126628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVIaMgOhMNcr"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL4qXsUVMAvx"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data_rescaled = scaler.fit_transform(train.drop('RUL', axis = 1))\n",
        "# 95% of variance\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 12)\n",
        "pca.fit(data_rescaled)\n",
        "reduced = pca.transform(data_rescaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMglbWb1MMh9",
        "outputId": "d52bf8cf-9254-4bcc-ca7f-7c228aa8d2cb"
      },
      "source": [
        "print(reduced.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20631, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpRJsTM1Pi10",
        "outputId": "af0edd3d-672d-4d31-8b8e-8e0ef758493b"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20631, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hK1wWi9N-Jh",
        "outputId": "d71c58b2-214f-4da9-cb8a-78321150e404"
      },
      "source": [
        "test_re = scaler.transform(test2)\n",
        "test_re.shape\n",
        "test3 = pca.transform(test_re)\n",
        "test3.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nwAOuTtORCp",
        "outputId": "597d6545-e0ae-4395-d476-3435133bbc4b"
      },
      "source": [
        "X_train_new = reduced\n",
        "X_test_new = test3\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRFRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "model = XGBRFRegressor(n_estimators=300, subsample=0.9, colsample_bynode=0.2, n_fold = 5, eval_metric = 'rmse')\n",
        "model.fit(X_train_new, y_train)\n",
        "y_pred = model.predict(X_test_new)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "print(\"Random Forest Mean Squared Error: \", mean_squared_error(y_true_new, y_pred))\n",
        "print(\"Random Forest Mean Absolute Error: \", mean_absolute_error(y_true_new, y_pred))\n",
        "print(\"Random Forest r-squared: \", r2_score(y_true_new, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14:09:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Random Forest Mean Squared Error:  1200.69105923701\n",
            "Random Forest Mean Absolute Error:  29.53411735534668\n",
            "Random Forest r-squared:  0.3047007954526444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "sbbmHNZMUZvd",
        "outputId": "c7471974-3e19-4f26-bf93-29fbfbb60851"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "gb = GradientBoostingRegressor()\n",
        "# set up 5-fold cross-validation\n",
        "from sklearn import model_selection\n",
        "cv = model_selection.KFold(5)\n",
        "# pipeline standardization and model\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipeline = Pipeline(steps=[('standardize', preprocessing.StandardScaler())\n",
        "                           , ('model', gb) ])\n",
        "# tune the model\n",
        "my_alpha = [.5, .75, .9]\n",
        "my_n_estimators= [500]\n",
        "my_learning_rate = [0.005, .01]\n",
        "my_max_depth = [4, 5, 6]\n",
        "# run the model using gridsearch, select the model with best search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "optimized_gb = GridSearchCV(estimator=pipeline\n",
        "                            , cv=cv\n",
        "                            , param_grid =dict(model__max_depth = my_max_depth, model__n_estimators = my_n_estimators,\n",
        "                                              model__learning_rate = my_learning_rate, model__alpha = my_alpha)\n",
        "                            , scoring = 'neg_mean_squared_error'\n",
        "                            , verbose = 1\n",
        "                            , n_jobs = -1\n",
        "                           )\n",
        "optimized_gb.fit(X_train, y_train)\n",
        "# show the best model estimators\n",
        "print(optimized_gb.best_estimator_)\n",
        "# evaluate metrics on holdout\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "y_pred = optimized_gb.predict(X_test)\n",
        "print(\"Gradient Boosting Mean Squared Error: \", mean_squared_error(y_test, y_pred))\n",
        "print(\"Gradient Boosting Mean Absolute Error: \", mean_absolute_error(y_test, y_pred))\n",
        "print(\"Gradient Boosting r-squared: \", r2_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-af92348d7943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                             \u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                            )\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0moptimized_gb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m# show the best model estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized_gb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8PJ4gSbgvEg"
      },
      "source": [
        "## Deep learning - classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqU3D3uBaJIv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Q4dzLj69czTm",
        "outputId": "63788505-1c2a-4e8f-c89a-475b7c126a62"
      },
      "source": [
        "dataset_train=pd.read_csv('/content/train_FD001.txt',sep=' ',header=None).drop([26,27],axis=1)\n",
        "col_names = ['id','cycle','setting1','setting2','setting3','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11','s12','s13','s14','s15','s16','s17','s18','s19','s20','s21']\n",
        "dataset_train.columns=col_names\n",
        "print('Shape of Train dataset: ',dataset_train.shape)\n",
        "dataset_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Train dataset:  (20631, 26)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  setting3  ...  s17   s18    s19    s20      s21\n",
              "0   1      1   -0.0007   -0.0004     100.0  ...  392  2388  100.0  39.06  23.4190\n",
              "1   1      2    0.0019   -0.0003     100.0  ...  392  2388  100.0  39.00  23.4236\n",
              "2   1      3   -0.0043    0.0003     100.0  ...  390  2388  100.0  38.95  23.3442\n",
              "3   1      4    0.0007    0.0000     100.0  ...  392  2388  100.0  38.88  23.3739\n",
              "4   1      5   -0.0019   -0.0002     100.0  ...  393  2388  100.0  38.90  23.4044\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "JIubYw6Hc5he",
        "outputId": "7822237c-e3a0-4c9b-ae13-9e7712f08f42"
      },
      "source": [
        "dataset_test=pd.read_csv('/content/test_FD001.txt',sep=' ',header=None).drop([26,27],axis=1)\n",
        "dataset_test.columns=col_names\n",
        "#dataset_test.head()\n",
        "print('Shape of Test dataset: ',dataset_train.shape)\n",
        "dataset_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Test dataset:  (20631, 26)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "      <th>s7</th>\n",
              "      <th>s8</th>\n",
              "      <th>s9</th>\n",
              "      <th>s10</th>\n",
              "      <th>s11</th>\n",
              "      <th>s12</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.3</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cycle  setting1  setting2  setting3  ...  s17   s18    s19    s20      s21\n",
              "0   1      1   -0.0007   -0.0004     100.0  ...  392  2388  100.0  39.06  23.4190\n",
              "1   1      2    0.0019   -0.0003     100.0  ...  392  2388  100.0  39.00  23.4236\n",
              "2   1      3   -0.0043    0.0003     100.0  ...  390  2388  100.0  38.95  23.3442\n",
              "3   1      4    0.0007    0.0000     100.0  ...  392  2388  100.0  38.88  23.3739\n",
              "4   1      5   -0.0019   -0.0002     100.0  ...  393  2388  100.0  38.90  23.4044\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Qj8xqPnPdCEm",
        "outputId": "71c81997-c73d-412e-da9e-bc8d896f7880"
      },
      "source": [
        "rul = pd.DataFrame(dataset_test.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "rul.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  max\n",
              "0   1   31\n",
              "1   2   49\n",
              "2   3  126\n",
              "3   4  106\n",
              "4   5   98"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "C6Rtwk-mdKMl",
        "outputId": "4d7bd688-8994-480e-d7c4-910695adf9c6"
      },
      "source": [
        "pm_truth=pd.read_csv('/content/RUL_FD001.txt',sep=' ',header=None).drop([1],axis=1)\n",
        "pm_truth.columns=['more']\n",
        "pm_truth['id']=pm_truth.index+1\n",
        "pm_truth.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>more</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>112</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   more  id\n",
              "0   112   1\n",
              "1    98   2\n",
              "2    69   3\n",
              "3    82   4\n",
              "4    91   5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "IHgZfHKWdS8q",
        "outputId": "4aaf3c31-a2f9-43b8-be62-5571acac242a"
      },
      "source": [
        "pm_truth['rtf']=pm_truth['more']+rul['max']\n",
        "pm_truth.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>more</th>\n",
              "      <th>id</th>\n",
              "      <th>rtf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>112</td>\n",
              "      <td>1</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98</td>\n",
              "      <td>2</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69</td>\n",
              "      <td>3</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82</td>\n",
              "      <td>4</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91</td>\n",
              "      <td>5</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   more  id  rtf\n",
              "0   112   1  143\n",
              "1    98   2  147\n",
              "2    69   3  195\n",
              "3    82   4  188\n",
              "4    91   5  189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByRoLUvMdWHz"
      },
      "source": [
        "pm_truth.drop('more', axis=1, inplace=True)\n",
        "dataset_test=dataset_test.merge(pm_truth,on=['id'],how='left')\n",
        "dataset_test['ttf']=dataset_test['rtf'] - dataset_test['cycle']\n",
        "dataset_test.drop('rtf', axis=1, inplace=True)\n",
        "dataset_test.head()\n",
        "\n",
        "dataset_train['ttf'] = dataset_train.groupby(['id'])['cycle'].transform(max)-dataset_train['cycle']\n",
        "dataset_train.head()\n",
        "\n",
        "df_train=dataset_train.copy()\n",
        "df_test=dataset_test.copy()\n",
        "period=30\n",
        "df_train['label_bc'] = df_train['ttf'].apply(lambda x: 1 if x <= period else 0)\n",
        "df_test['label_bc'] = df_test['ttf'].apply(lambda x: 1 if x <= period else 0)\n",
        "df_train.head()\n",
        "\n",
        "features_col_name=['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',\n",
        "                   's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "target_col_name='label_bc'\n",
        "\n",
        "sc=MinMaxScaler()\n",
        "df_train[features_col_name]=sc.fit_transform(df_train[features_col_name])\n",
        "df_test[features_col_name]=sc.transform(df_test[features_col_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l91koAVJeVUp"
      },
      "source": [
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    df_zeros=pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n",
        "    id_df=df_zeros.append(id_df,ignore_index=True)\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    lstm_array=[]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        lstm_array.append(data_array[start:stop, :])\n",
        "    return np.array(lstm_array)\n",
        "\n",
        "# function to generate labels\n",
        "def gen_label(id_df, seq_length, seq_cols,label):\n",
        "    df_zeros=pd.DataFrame(np.zeros((seq_length-1,id_df.shape[1])),columns=id_df.columns)\n",
        "    id_df=df_zeros.append(id_df,ignore_index=True)\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    y_label=[]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        y_label.append(id_df[label][stop])\n",
        "    return np.array(y_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr3KgBQCeYWm",
        "outputId": "7ddb96be-212c-4a8c-9514-aebf3a031047"
      },
      "source": [
        "seq_length=50\n",
        "seq_cols=features_col_name\n",
        "\n",
        "# generate X_train\n",
        "X_train=np.concatenate(list(list(gen_sequence(df_train[df_train['id']==id], seq_length, seq_cols)) for id in df_train['id'].unique()))\n",
        "print(X_train.shape)\n",
        "# generate y_train\n",
        "y_train=np.concatenate(list(list(gen_label(df_train[df_train['id']==id], 50, seq_cols,'label_bc')) for id in df_train['id'].unique()))\n",
        "print(y_train.shape)\n",
        "\n",
        "# generate X_test\n",
        "X_test=np.concatenate(list(list(gen_sequence(df_test[df_test['id']==id], seq_length, seq_cols)) for id in df_test['id'].unique()))\n",
        "print(X_test.shape)\n",
        "# generate y_test\n",
        "y_test=np.concatenate(list(list(gen_label(df_test[df_test['id']==id], 50, seq_cols,'label_bc')) for id in df_test['id'].unique()))\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20531, 50, 24)\n",
            "(20531,)\n",
            "(12996, 50, 24)\n",
            "(12996,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC1zOcGvehfC",
        "outputId": "db80be5d-aac9-432b-ff1a-0ac615006ada"
      },
      "source": [
        "nb_features =X_train.shape[2]\n",
        "timestamp=seq_length\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(\n",
        "         input_shape=(timestamp, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 50, 100)           50000     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 80,251\n",
            "Trainable params: 80,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR4ldTDRe9AR",
        "outputId": "61e893d7-7b13-4f2f-9464-eb3261cdcbb0"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=200, validation_split=0.05, verbose=1,\n",
        "          callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "98/98 [==============================] - 26s 228ms/step - loss: 0.3198 - accuracy: 0.8775 - val_loss: 0.0826 - val_accuracy: 0.9659\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 21s 217ms/step - loss: 0.0800 - accuracy: 0.9693 - val_loss: 0.0715 - val_accuracy: 0.9659\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 21s 218ms/step - loss: 0.0680 - accuracy: 0.9713 - val_loss: 0.0491 - val_accuracy: 0.9834\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 21s 217ms/step - loss: 0.0664 - accuracy: 0.9724 - val_loss: 0.0613 - val_accuracy: 0.9679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e19d913c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKb7aTt7fs9e",
        "outputId": "e40f6b3a-0c57-45ca-eb50-018824df94e4"
      },
      "source": [
        "scores = model.evaluate(X_train, y_train, verbose=1, batch_size=200)\n",
        "print('Accurracy: {}'.format(scores[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103/103 [==============================] - 8s 75ms/step - loss: 0.0580 - accuracy: 0.9762\n",
            "Accurracy: 0.9761823415756226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieUu_rElf1xC",
        "outputId": "33502476-a7bb-4835-dbb9-37d713f7a713"
      },
      "source": [
        "y_pred=model.predict_classes(X_test)\n",
        "print('Accuracy of model on test data: ',accuracy_score(y_test,y_pred))\n",
        "print('Confusion Matrix: \\n',confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model on test data:  0.9901508156355802\n",
            "Confusion Matrix: \n",
            " [[12645    19]\n",
            " [  109   223]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJK1nNis9Xjt"
      },
      "source": [
        "## Deep learning - regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTDI5HpBD7HP"
      },
      "source": [
        "-- TEST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNvZFGx5_pdl"
      },
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers.core import Activation\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Setting seed for reproducibility\n",
        "np.random.seed(1234)  \n",
        "PYTHONHASHSEED = 0\n",
        "\n",
        "# define path to save model\n",
        "model_path = '/content/Output/regression_model.h5'\n",
        "\n",
        "##################################\n",
        "# Data Ingestion\n",
        "##################################\n",
        "\n",
        "# read training data - It is the aircraft engine run-to-failure data.\n",
        "train_df = pd.read_csv('/content/train_FD001.txt', sep=\" \", header=None)\n",
        "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "\n",
        "train_df = train_df.sort_values(['id','cycle'])\n",
        "\n",
        "# read test data - It is the aircraft engine operating data without failure events recorded.\n",
        "test_df = pd.read_csv('/content/test_FD001.txt', sep=\" \", header=None)\n",
        "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "\n",
        "# read ground truth data - It contains the information of true remaining cycles for each engine in the testing data.\n",
        "truth_df = pd.read_csv('/content/RUL_FD001.txt', sep=\" \", header=None)\n",
        "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkEBlNSLAA5i"
      },
      "source": [
        "##################################\n",
        "# Prepare training data\n",
        "##################################\n",
        "\n",
        "# Data Labeling - generate column RUL(Remaining Usefull Life or Time to Failure)\n",
        "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "train_df = train_df.merge(rul, on=['id'], how='left')\n",
        "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
        "train_df.drop('max', axis=1, inplace=True)\n",
        "\n",
        "# generate label columns for training data\n",
        "# we will only make use of \"label1\" for binary classification, \n",
        "# while trying to answer the question: is a specific engine going to fail within w1 cycles?\n",
        "w1 = 30\n",
        "w0 = 15\n",
        "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
        "train_df['label2'] = train_df['label1']\n",
        "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
        "\n",
        "# MinMax normalization (from 0 to 1)\n",
        "train_df['cycle_norm'] = train_df['cycle']\n",
        "cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
        "                             columns=cols_normalize, \n",
        "                             index=train_df.index)\n",
        "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "train_df = join_df.reindex(columns = train_df.columns)\n",
        "\n",
        "#train_df.to_csv('../../Dataset/PredictiveManteinanceEngineTraining.csv', encoding='utf-8',index = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH9WL7nxAIgO",
        "outputId": "d7c56e4d-617c-4706-96af-d3f60f979cac"
      },
      "source": [
        "# MinMax normalization (from 0 to 1)\n",
        "test_df['cycle_norm'] = test_df['cycle']\n",
        "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
        "                            columns=cols_normalize, \n",
        "                            index=test_df.index)\n",
        "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
        "test_df = test_join_df.reindex(columns = test_df.columns)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "print(test_df.head())\n",
        "\n",
        "# We use the ground truth dataset to generate labels for the test data.\n",
        "# generate column max for test data\n",
        "rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "truth_df.columns = ['more']\n",
        "truth_df['id'] = truth_df.index + 1\n",
        "truth_df['max'] = rul['max'] + truth_df['more']\n",
        "truth_df.drop('more', axis=1, inplace=True)\n",
        "\n",
        "# generate RUL for test data\n",
        "test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
        "test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
        "test_df.drop('max', axis=1, inplace=True)\n",
        "\n",
        "# generate label columns w0 and w1 for test data\n",
        "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
        "test_df['label2'] = test_df['label1']\n",
        "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
        "\n",
        "#test_df.to_csv('../../Dataset/PredictiveManteinanceEngineValidation.csv', encoding='utf-8',index = None)\n",
        "\n",
        "# pick a large window size of 50 cycles\n",
        "sequence_length = 50\n",
        "\n",
        "# function to reshape features into (samples, time steps, features) \n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    # for one id I put all the rows in a single matrix\n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # Iterate over two lists in parallel.\n",
        "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
        "    # so zip iterate over two following list of numbers (0,112),(50,192)\n",
        "    # 0 50 -> from row 0 to row 50\n",
        "    # 1 51 -> from row 1 to row 51\n",
        "    # 2 52 -> from row 2 to row 52\n",
        "    # ...\n",
        "    # 111 191 -> from row 111 to 191\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "        \n",
        "# pick the feature columns \n",
        "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
        "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
        "sequence_cols.extend(sensor_cols)\n",
        "\n",
        "# TODO for debug \n",
        "# val is a list of 192 - 50 = 142 bi-dimensional array (50 rows x 25 columns)\n",
        "val=list(gen_sequence(train_df[train_df['id']==1], sequence_length, sequence_cols))\n",
        "print(len(val))\n",
        "\n",
        "# generator for the sequences\n",
        "# transform each id of the train dataset in a sequence\n",
        "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n",
        "           for id in train_df['id'].unique())\n",
        "\n",
        "# generate sequences and convert to numpy array\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "print(seq_array.shape)\n",
        "\n",
        "# function to generate labels\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    # For one id I put all the labels in a single matrix.\n",
        "    # For example:\n",
        "    # [[1]\n",
        "    # [4]\n",
        "    # [1]\n",
        "    # [5]\n",
        "    # [9]\n",
        "    # ...\n",
        "    # [200]] \n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # I have to remove the first seq_length labels\n",
        "    # because for one id the first sequence of seq_length size have as target\n",
        "    # the last label (the previus ones are discarded).\n",
        "    # All the next id's sequences will have associated step by step one label as target.\n",
        "    return data_matrix[seq_length:num_elements, :]\n",
        "\n",
        "# generate labels\n",
        "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL']) \n",
        "             for id in train_df['id'].unique()]\n",
        "\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "label_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  cycle  setting1  setting2  ...  s19       s20       s21  cycle_norm\n",
            "0   1      1  0.632184  0.750000  ...  0.0  0.558140  0.661834     0.00000\n",
            "1   1      2  0.344828  0.250000  ...  0.0  0.682171  0.686827     0.00277\n",
            "2   1      3  0.517241  0.583333  ...  0.0  0.728682  0.721348     0.00554\n",
            "3   1      4  0.741379  0.500000  ...  0.0  0.666667  0.662110     0.00831\n",
            "4   1      5  0.580460  0.500000  ...  0.0  0.658915  0.716377     0.01108\n",
            "\n",
            "[5 rows x 27 columns]\n",
            "142\n",
            "(15631, 50, 25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15631, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rnez56DATvA"
      },
      "source": [
        "def r2_keras(y_true, y_pred):\n",
        "    \"\"\"Coefficient of Determination \n",
        "    \"\"\"\n",
        "    SS_res =  K.sum(K.square( y_true - y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSK9Fp8uAV9u",
        "outputId": "63dc0c0d-7e24-49d4-dc2a-1d128d87697b"
      },
      "source": [
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(\n",
        "         input_shape=(sequence_length, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=nb_out))\n",
        "model.add(Activation(\"linear\"))\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae',r2_keras])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# fit the network\n",
        "history = model.fit(seq_array, label_array, epochs=5, batch_size=10, validation_split=0.05, verbose=2,\n",
        "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
        "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
        "          )\n",
        "\n",
        "# list all data in historytor\n",
        "print(history.hisy.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 50, 100)           50400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 80,651\n",
            "Trainable params: 80,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1485/1485 - 65s - loss: 5425.7373 - mae: 56.2750 - r2_keras: -9.6752e-01 - val_loss: 3321.9636 - val_mae: 45.6554 - val_r2_keras: -6.2779e+02\n",
            "Epoch 2/5\n",
            "1485/1485 - 62s - loss: 2435.5864 - mae: 35.3442 - r2_keras: 0.1901 - val_loss: 1301.5200 - val_mae: 23.5364 - val_r2_keras: -1.5351e+02\n",
            "Epoch 3/5\n",
            "1485/1485 - 61s - loss: 1070.9786 - mae: 20.9381 - r2_keras: 0.6493 - val_loss: 756.1752 - val_mae: 17.9181 - val_r2_keras: -8.8957e+01\n",
            "Epoch 4/5\n",
            "1485/1485 - 62s - loss: 852.0287 - mae: 18.7493 - r2_keras: 0.7114 - val_loss: 653.5129 - val_mae: 16.4397 - val_r2_keras: -7.8027e+01\n",
            "Epoch 5/5\n",
            "1485/1485 - 62s - loss: 738.2304 - mae: 17.4801 - r2_keras: 0.7463 - val_loss: 656.4995 - val_mae: 17.3518 - val_r2_keras: -7.7288e+01\n",
            "dict_keys(['loss', 'mae', 'r2_keras', 'val_loss', 'val_mae', 'val_r2_keras'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6Go_OEQAcM7"
      },
      "source": [
        "# Save the training history\n",
        "import pickle\n",
        "filename = open(\"/content/Output/rul_point_regression_model_history\",\"wb\")\n",
        "pickle.dump(history.history, filename)\n",
        "filename.close()\n",
        "        \n",
        "history_file = open('/content/Output/rul_point_regression_model_history','rb')\n",
        "saved_history = pickle.load(history_file)\n",
        "history_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD4j6LU4AgO5",
        "outputId": "3e6f205d-1410-4f43-89b5-6df09554b4fe"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"/content/Output/rul_point_regression_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/Output/rul_point_regression_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wccwpVOAugd",
        "outputId": "1d8f534b-8ef5-4063-bc9e-9cd58e57430c"
      },
      "source": [
        "import pickle\n",
        "history_file = open(\"/content/Output/rul_point_regression_model_history\",\"rb\")\n",
        "saved_history = pickle.load(history_file)\n",
        "history_file.close()\n",
        "\n",
        "# Load model from disk\n",
        "from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open(\"/content/Output/rul_point_regression_model.json\", \"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/Output/rul_point_regression_model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZukmasWA7AE",
        "outputId": "d19e6e80-06a8-4f4a-a7f5-3d64a3165c91"
      },
      "source": [
        "\n",
        "\n",
        "# training metrics\n",
        "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
        "print('\\nMAE: {}'.format(scores[1]))\n",
        "print('\\nR^2: {}'.format(scores[2]))\n",
        "\n",
        "y_pred = model.predict(seq_array,verbose=1, batch_size=200)\n",
        "y_true = label_array\n",
        "\n",
        "test_set = pd.DataFrame(y_pred)\n",
        "test_set.to_csv('/content/Output/submit_train.csv', index = None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 7s 87ms/step - loss: 707.7202 - mae: 15.8125 - r2_keras: 0.7807\n",
            "\n",
            "MAE: 15.81248664855957\n",
            "\n",
            "R^2: 0.7806795835494995\n",
            "79/79 [==============================] - 7s 84ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrUtsLmOBFEW",
        "outputId": "56c1ecdf-7906-4ea5-c673-f0c2704d1c01"
      },
      "source": [
        "truth_df = pd.read_csv('/content/RUL_FD001.txt', sep=\" \", header=None)\n",
        "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)\n",
        "\n",
        "test_df = pd.read_csv('/content/test_FD001.txt', sep=\" \", header=None)\n",
        "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "test_df['cycle_norm'] = test_df['cycle']\n",
        "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
        "                            columns=cols_normalize, \n",
        "                            index=test_df.index)\n",
        "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
        "test_df = test_join_df.reindex(columns = test_df.columns)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "print(test_df.head())\n",
        "\n",
        "# We use the ground truth dataset to generate labels for the test data.\n",
        "# generate column max for test data\n",
        "rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "truth_df.columns = ['more']\n",
        "truth_df['id'] = truth_df.index + 1\n",
        "truth_df['max'] = rul['max'] + truth_df['more']\n",
        "truth_df.drop('more', axis=1, inplace=True)\n",
        "\n",
        "# generate RUL for test data\n",
        "test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
        "test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
        "test_df.drop('max', axis=1, inplace=True)\n",
        "\n",
        "# generate label columns w0 and w1 for test data\n",
        "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
        "test_df['label2'] = test_df['label1']\n",
        "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  cycle  setting1  setting2  ...  s19       s20       s21  cycle_norm\n",
            "0   1      1  0.632184  0.750000  ...  0.0  0.558140  0.661834     0.00000\n",
            "1   1      2  0.344828  0.250000  ...  0.0  0.682171  0.686827     0.00277\n",
            "2   1      3  0.517241  0.583333  ...  0.0  0.728682  0.721348     0.00554\n",
            "3   1      4  0.741379  0.500000  ...  0.0  0.666667  0.662110     0.00831\n",
            "4   1      5  0.580460  0.500000  ...  0.0  0.658915  0.716377     0.01108\n",
            "\n",
            "[5 rows x 27 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qJTTGGODBNsE",
        "outputId": "5aec42e9-8c47-4002-a2c3-657b31b99cd9"
      },
      "source": [
        "# We pick the last sequence for each id in the test data\n",
        "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] \n",
        "                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
        "\n",
        "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
        "print(\"seq_array_test_last\")\n",
        "#print(seq_array_test_last)\n",
        "print(seq_array_test_last.shape)\n",
        "\n",
        "# Similarly, we pick the labels\n",
        "#print(\"y_mask\")\n",
        "y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]\n",
        "label_array_test_last = test_df.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
        "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
        "print(label_array_test_last.shape)\n",
        "print(\"label_array_test_last\")\n",
        "print(label_array_test_last)\n",
        "print(seq_array_test_last)\n",
        "# if best iteration's model was saved then load and use it\n",
        "if os.path.isfile(model_path):\n",
        "    estimator = load_model(model_path,custom_objects={'r2_keras': r2_keras})\n",
        "\n",
        "    # test metrics\n",
        "    scores_test = estimator.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n",
        "    print('\\nMAE: {}'.format(scores_test[1]))\n",
        "    print('\\nR^2: {}'.format(scores_test[2]))\n",
        "\n",
        "    y_pred_test = estimator.predict(seq_array_test_last)\n",
        "    y_true_test = label_array_test_last\n",
        "\n",
        "    test_set = pd.DataFrame(y_pred_test)\n",
        "    test_set.to_csv('/content/Output/submit_test.csv', index = None)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seq_array_test_last\n",
            "(93, 50, 25)\n",
            "(93, 1)\n",
            "label_array_test_last\n",
            "[[ 69.]\n",
            " [ 82.]\n",
            " [ 91.]\n",
            " [ 93.]\n",
            " [ 91.]\n",
            " [ 95.]\n",
            " [111.]\n",
            " [ 96.]\n",
            " [ 97.]\n",
            " [124.]\n",
            " [ 95.]\n",
            " [ 83.]\n",
            " [ 84.]\n",
            " [ 50.]\n",
            " [ 28.]\n",
            " [ 87.]\n",
            " [ 16.]\n",
            " [ 57.]\n",
            " [113.]\n",
            " [ 20.]\n",
            " [119.]\n",
            " [ 66.]\n",
            " [ 97.]\n",
            " [ 90.]\n",
            " [115.]\n",
            " [  8.]\n",
            " [ 48.]\n",
            " [106.]\n",
            " [  7.]\n",
            " [ 11.]\n",
            " [ 19.]\n",
            " [ 21.]\n",
            " [ 50.]\n",
            " [ 28.]\n",
            " [ 18.]\n",
            " [ 10.]\n",
            " [ 59.]\n",
            " [109.]\n",
            " [114.]\n",
            " [ 47.]\n",
            " [135.]\n",
            " [ 92.]\n",
            " [ 21.]\n",
            " [ 79.]\n",
            " [114.]\n",
            " [ 29.]\n",
            " [ 26.]\n",
            " [ 97.]\n",
            " [137.]\n",
            " [ 15.]\n",
            " [103.]\n",
            " [ 37.]\n",
            " [114.]\n",
            " [100.]\n",
            " [ 21.]\n",
            " [ 54.]\n",
            " [ 72.]\n",
            " [ 28.]\n",
            " [128.]\n",
            " [ 14.]\n",
            " [ 77.]\n",
            " [  8.]\n",
            " [121.]\n",
            " [ 94.]\n",
            " [118.]\n",
            " [ 50.]\n",
            " [131.]\n",
            " [126.]\n",
            " [113.]\n",
            " [ 10.]\n",
            " [ 34.]\n",
            " [107.]\n",
            " [ 63.]\n",
            " [ 90.]\n",
            " [  8.]\n",
            " [  9.]\n",
            " [137.]\n",
            " [ 58.]\n",
            " [ 89.]\n",
            " [116.]\n",
            " [115.]\n",
            " [136.]\n",
            " [ 28.]\n",
            " [ 38.]\n",
            " [ 20.]\n",
            " [ 85.]\n",
            " [ 55.]\n",
            " [128.]\n",
            " [137.]\n",
            " [ 82.]\n",
            " [ 59.]\n",
            " [117.]\n",
            " [ 20.]]\n",
            "[[[0.3505747  0.8333333  0.         ... 0.         0.4728682  0.45457056]\n",
            "  [0.39655173 0.5833333  0.         ... 0.         0.6511628  0.5608948 ]\n",
            "  [0.5114943  0.25       0.         ... 0.         0.6356589  0.4975145 ]\n",
            "  ...\n",
            "  [0.43678162 0.75       0.         ... 0.         0.41860464 0.4710025 ]\n",
            "  [0.5804598  0.6666667  0.         ... 0.         0.3255814  0.45954156]\n",
            "  [0.40804598 0.8333333  0.         ... 0.         0.6124031  0.52444077]]\n",
            "\n",
            " [[0.55172414 0.25       0.         ... 0.         0.5503876  0.6974593 ]\n",
            "  [0.39655173 0.5833333  0.         ... 0.         0.37209302 0.59748685]\n",
            "  [0.5344828  0.16666667 0.         ... 0.         0.51937985 0.602596  ]\n",
            "  ...\n",
            "  [0.43103448 0.33333334 0.         ... 0.         0.56589144 0.49461475]\n",
            "  [0.33908045 0.25       0.         ... 0.         0.4108527  0.5223695 ]\n",
            "  [0.5689655  0.8333333  0.         ... 0.         0.34108528 0.5024855 ]]\n",
            "\n",
            " [[0.7356322  0.25       0.         ... 0.         0.53488374 0.6023198 ]\n",
            "  [0.67241377 0.16666667 0.         ... 0.         0.58914727 0.68102735]\n",
            "  [0.43678162 0.5        0.         ... 0.         0.58914727 0.546396  ]\n",
            "  ...\n",
            "  [0.5689655  0.33333334 0.         ... 0.         0.5503876  0.4584369 ]\n",
            "  [0.29885057 0.5        0.         ... 0.         0.41860464 0.5625518 ]\n",
            "  [0.42528737 0.16666667 0.         ... 0.         0.4728682  0.7145816 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.49425286 0.75       0.         ... 0.         0.6666667  0.45042807]\n",
            "  [0.28735632 0.33333334 0.         ... 0.         0.627907   0.6255178 ]\n",
            "  [0.31034482 0.16666667 0.         ... 0.         0.44186047 0.4710025 ]\n",
            "  ...\n",
            "  [0.6436782  0.41666666 0.         ... 0.         0.4496124  0.51367027]\n",
            "  [0.4827586  0.33333334 0.         ... 0.         0.4883721  0.5015189 ]\n",
            "  [0.59770113 0.5833333  0.         ... 0.         0.48062015 0.6442972 ]]\n",
            "\n",
            " [[0.6896552  0.75       0.         ... 0.         0.76744187 0.51795083]\n",
            "  [0.47126436 0.16666667 0.         ... 0.         0.6124031  0.77492404]\n",
            "  [0.61494255 0.33333334 0.         ... 0.         0.68992245 0.7954985 ]\n",
            "  ...\n",
            "  [0.33908045 0.75       0.         ... 0.         0.7209302  0.54045844]\n",
            "  [0.41954023 0.33333334 0.         ... 0.         0.64341086 0.7702292 ]\n",
            "  [0.77011496 0.5        0.         ... 0.         0.627907   0.64250207]]\n",
            "\n",
            " [[0.47126436 0.5833333  0.         ... 0.         0.68217057 0.59279203]\n",
            "  [0.6091954  0.5833333  0.         ... 0.         0.60465115 0.62510353]\n",
            "  [0.55172414 0.6666667  0.         ... 0.         0.5968992  0.49047226]\n",
            "  ...\n",
            "  [0.46551725 0.25       0.         ... 0.         0.37209302 0.4293013 ]\n",
            "  [0.2816092  0.5833333  0.         ... 0.         0.4031008  0.51877934]\n",
            "  [0.57471263 0.75       0.         ... 0.         0.43410853 0.40223694]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ed45e2c16ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# test metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mscores_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_array_test_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_array_test_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nMAE: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nR^2: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1219 run_step  **\n        with ops.control_dependencies(_minimum_control_deps(outputs)):\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2793 _minimum_control_deps\n        outputs = nest.flatten(outputs, expand_composites=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:341 flatten\n        return _pywrap_utils.Flatten(structure, expand_composites)\n\n    TypeError: '<' not supported between instances of 'function' and 'str'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNqiD0RwIgjy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cku8FFoOzzW"
      },
      "source": [
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers.core import Activation\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Setting seed for reproducibility\n",
        "np.random.seed(1234)  \n",
        "PYTHONHASHSEED = 0\n",
        "\n",
        "# define path to save model\n",
        "model_path = 'regression_model.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1722LD6P0vI"
      },
      "source": [
        "# read training data - It is the aircraft engine run-to-failure data.\n",
        "train_df = pd.read_csv('/content/train_FD001.txt', sep=\" \", header=None)\n",
        "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "\n",
        "train_df = train_df.sort_values(['id','cycle'])\n",
        "\n",
        "# read test data - It is the aircraft engine operating data without failure events recorded.\n",
        "test_df = pd.read_csv('/content/test_FD001.txt', sep=\" \", header=None)\n",
        "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
        "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
        "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
        "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "\n",
        "# read ground truth data - It contains the information of true remaining cycles for each engine in the testing data.\n",
        "truth_df = pd.read_csv('/content/RUL_FD001.txt', sep=\" \", header=None)\n",
        "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLtCyI1KQBVv",
        "outputId": "5ac3c399-0f6f-4392-a035-760135929e1d"
      },
      "source": [
        "##################################\n",
        "# Data Preprocessing\n",
        "##################################\n",
        "\n",
        "#######\n",
        "# TRAIN\n",
        "#######\n",
        "# Data Labeling - generate column RUL(Remaining Usefull Life or Time to Failure)\n",
        "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "train_df = train_df.merge(rul, on=['id'], how='left')\n",
        "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
        "train_df.drop('max', axis=1, inplace=True)\n",
        "\n",
        "# generate label columns for training data\n",
        "# we will only make use of \"label1\" for binary classification, \n",
        "# while trying to answer the question: is a specific engine going to fail within w1 cycles?\n",
        "w1 = 30\n",
        "w0 = 15\n",
        "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
        "train_df['label2'] = train_df['label1']\n",
        "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
        "\n",
        "# MinMax normalization (from 0 to 1)\n",
        "train_df['cycle_norm'] = train_df['cycle']\n",
        "cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
        "                             columns=cols_normalize, \n",
        "                             index=train_df.index)\n",
        "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "train_df = join_df.reindex(columns = train_df.columns)\n",
        "\n",
        "#train_df.to_csv('PredictiveManteinanceEngineTraining.csv', encoding='utf-8',index = None)\n",
        "\n",
        "######\n",
        "# TEST\n",
        "######\n",
        "# MinMax normalization (from 0 to 1)\n",
        "test_df['cycle_norm'] = test_df['cycle']\n",
        "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
        "                            columns=cols_normalize, \n",
        "                            index=test_df.index)\n",
        "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
        "test_df = test_join_df.reindex(columns = test_df.columns)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "print(test_df.head())\n",
        "\n",
        "# We use the ground truth dataset to generate labels for the test data.\n",
        "# generate column max for test data\n",
        "rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
        "rul.columns = ['id', 'max']\n",
        "truth_df.columns = ['more']\n",
        "truth_df['id'] = truth_df.index + 1\n",
        "truth_df['max'] = rul['max'] + truth_df['more']\n",
        "truth_df.drop('more', axis=1, inplace=True)\n",
        "\n",
        "# generate RUL for test data\n",
        "test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
        "test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
        "test_df.drop('max', axis=1, inplace=True)\n",
        "\n",
        "# generate label columns w0 and w1 for test data\n",
        "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
        "test_df['label2'] = test_df['label1']\n",
        "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
        "\n",
        "#test_df.to_csv('PredictiveManteinanceEngineValidation.csv', encoding='utf-8',index = None)\n",
        "\n",
        "# pick a large window size of 50 cycles\n",
        "sequence_length = 50\n",
        "\n",
        "# function to reshape features into (samples, time steps, features) \n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "        \n",
        "# pick the feature columns \n",
        "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
        "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
        "sequence_cols.extend(sensor_cols)\n",
        "\n",
        "# TODO for debug \n",
        "# val is a list of 192 - 50 = 142 bi-dimensional array (50 rows x 25 columns)\n",
        "val=list(gen_sequence(train_df[train_df['id']==1], sequence_length, sequence_cols))\n",
        "print(len(val))\n",
        "\n",
        "# generator for the sequences\n",
        "# transform each id of the train dataset in a sequence\n",
        "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n",
        "           for id in train_df['id'].unique())\n",
        "\n",
        "# generate sequences and convert to numpy array\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "print(seq_array.shape)\n",
        "\n",
        "# function to generate labels\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
        "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
        "    we can use shorter ones \"\"\"\n",
        "    # For one id I put all the labels in a single matrix.\n",
        "    # For example:\n",
        "    # [[1]\n",
        "    # [4]\n",
        "    # [1]\n",
        "    # [5]\n",
        "    # [9]\n",
        "    # ...\n",
        "    # [200]] \n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    # I have to remove the first seq_length labels\n",
        "    # because for one id the first sequence of seq_length size have as target\n",
        "    # the last label (the previus ones are discarded).\n",
        "    # All the next id's sequences will have associated step by step one label as target.\n",
        "    return data_matrix[seq_length:num_elements, :]\n",
        "\n",
        "# generate labels\n",
        "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL']) \n",
        "             for id in train_df['id'].unique()]\n",
        "\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "label_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  cycle  setting1  setting2  ...  s19       s20       s21  cycle_norm\n",
            "0   1      1  0.632184  0.750000  ...  0.0  0.558140  0.661834     0.00000\n",
            "1   1      2  0.344828  0.250000  ...  0.0  0.682171  0.686827     0.00277\n",
            "2   1      3  0.517241  0.583333  ...  0.0  0.728682  0.721348     0.00554\n",
            "3   1      4  0.741379  0.500000  ...  0.0  0.666667  0.662110     0.00831\n",
            "4   1      5  0.580460  0.500000  ...  0.0  0.658915  0.716377     0.01108\n",
            "\n",
            "[5 rows x 27 columns]\n",
            "142\n",
            "(15631, 50, 25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15631, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqnsUE-_QJ28",
        "outputId": "dee03485-9dcb-482c-8944-727640f9ba57"
      },
      "source": [
        "def r2_keras(y_true, y_pred):\n",
        "    \"\"\"Coefficient of Determination \n",
        "    \"\"\"\n",
        "    SS_res =  K.sum(K.square( y_true - y_pred ))\n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "\n",
        "# Next, we build a deep network. \n",
        "# The first layer is an LSTM layer with 100 units followed by another LSTM layer with 50 units. \n",
        "# Dropout is also applied after each LSTM layer to control overfitting. \n",
        "# Final layer is a Dense output layer with single unit and linear activation since this is a regression problem.\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(\n",
        "         input_shape=(sequence_length, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=nb_out))\n",
        "model.add(Activation(\"linear\"))\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae',r2_keras])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# fit the network\n",
        "history = model.fit(seq_array, label_array, epochs=100, batch_size=200, validation_split=0.05, verbose=2,\n",
        "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
        "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
        "          )\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 50, 100)           50400     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 51        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 80,651\n",
            "Trainable params: 80,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "75/75 - 22s - loss: 8874.8193 - mae: 75.5153 - r2_keras: -1.7398e+00 - val_loss: 8288.5410 - val_mae: 72.6327 - val_r2_keras: -2.4892e+00\n",
            "Epoch 2/100\n",
            "75/75 - 18s - loss: 8191.0688 - mae: 71.5636 - r2_keras: -1.5242e+00 - val_loss: 7759.1362 - val_mae: 69.5544 - val_r2_keras: -2.2390e+00\n",
            "Epoch 3/100\n",
            "75/75 - 17s - loss: 7677.9014 - mae: 68.6166 - r2_keras: -1.3633e+00 - val_loss: 7260.1182 - val_mae: 66.6689 - val_r2_keras: -2.0049e+00\n",
            "Epoch 4/100\n",
            "75/75 - 17s - loss: 7188.6431 - mae: 65.7996 - r2_keras: -1.2155e+00 - val_loss: 6790.0005 - val_mae: 63.9695 - val_r2_keras: -1.7864e+00\n",
            "Epoch 5/100\n",
            "75/75 - 17s - loss: 6735.3848 - mae: 63.2323 - r2_keras: -1.0752e+00 - val_loss: 6350.7520 - val_mae: 61.4660 - val_r2_keras: -1.5843e+00\n",
            "Epoch 6/100\n",
            "75/75 - 17s - loss: 6305.0410 - mae: 60.7962 - r2_keras: -9.4044e-01 - val_loss: 5937.8706 - val_mae: 59.1320 - val_r2_keras: -1.3966e+00\n",
            "Epoch 7/100\n",
            "75/75 - 17s - loss: 5906.0566 - mae: 58.5691 - r2_keras: -8.1606e-01 - val_loss: 5555.8765 - val_mae: 56.9929 - val_r2_keras: -1.2252e+00\n",
            "Epoch 8/100\n",
            "75/75 - 17s - loss: 5529.8970 - mae: 56.5024 - r2_keras: -7.0461e-01 - val_loss: 5201.5562 - val_mae: 55.0317 - val_r2_keras: -1.0688e+00\n",
            "Epoch 9/100\n",
            "75/75 - 17s - loss: 5193.9697 - mae: 54.6808 - r2_keras: -5.9844e-01 - val_loss: 4875.7783 - val_mae: 53.2542 - val_r2_keras: -9.2776e-01\n",
            "Epoch 10/100\n",
            "75/75 - 17s - loss: 4883.6567 - mae: 53.0100 - r2_keras: -5.0443e-01 - val_loss: 4579.9443 - val_mae: 51.6658 - val_r2_keras: -8.0260e-01\n",
            "Epoch 11/100\n",
            "75/75 - 17s - loss: 4591.6074 - mae: 51.4848 - r2_keras: -4.1088e-01 - val_loss: 4312.4746 - val_mae: 50.2576 - val_r2_keras: -6.9264e-01\n",
            "Epoch 12/100\n",
            "75/75 - 17s - loss: 4339.6162 - mae: 50.1882 - r2_keras: -3.3211e-01 - val_loss: 4074.3044 - val_mae: 49.0353 - val_r2_keras: -5.9825e-01\n",
            "Epoch 13/100\n",
            "75/75 - 17s - loss: 4108.7568 - mae: 49.0656 - r2_keras: -2.6137e-01 - val_loss: 3863.8606 - val_mae: 47.9917 - val_r2_keras: -5.1877e-01\n",
            "Epoch 14/100\n",
            "75/75 - 17s - loss: 3913.3582 - mae: 48.1477 - r2_keras: -2.0074e-01 - val_loss: 3685.0544 - val_mae: 47.1423 - val_r2_keras: -4.5552e-01\n",
            "Epoch 15/100\n",
            "75/75 - 17s - loss: 3748.8289 - mae: 47.3684 - r2_keras: -1.5047e-01 - val_loss: 3532.7756 - val_mae: 46.4619 - val_r2_keras: -4.0652e-01\n",
            "Epoch 16/100\n",
            "75/75 - 17s - loss: 3608.0005 - mae: 46.8752 - r2_keras: -1.0703e-01 - val_loss: 3407.2539 - val_mae: 45.9537 - val_r2_keras: -3.7183e-01\n",
            "Epoch 17/100\n",
            "75/75 - 17s - loss: 3495.5044 - mae: 46.3929 - r2_keras: -7.4003e-02 - val_loss: 3309.0002 - val_mae: 45.6149 - val_r2_keras: -3.5144e-01\n",
            "Epoch 18/100\n",
            "75/75 - 17s - loss: 3407.4099 - mae: 46.1650 - r2_keras: -4.6124e-02 - val_loss: 3243.5410 - val_mae: 45.4540 - val_r2_keras: -3.4497e-01\n",
            "Epoch 19/100\n",
            "75/75 - 17s - loss: 3354.9949 - mae: 46.0652 - r2_keras: -3.0645e-02 - val_loss: 3199.8044 - val_mae: 45.4206 - val_r2_keras: -3.4898e-01\n",
            "Epoch 20/100\n",
            "75/75 - 17s - loss: 3327.9275 - mae: 46.1523 - r2_keras: -2.0896e-02 - val_loss: 3177.1025 - val_mae: 45.4851 - val_r2_keras: -3.6035e-01\n",
            "Epoch 21/100\n",
            "75/75 - 17s - loss: 3309.6362 - mae: 46.2065 - r2_keras: -1.7021e-02 - val_loss: 3169.7861 - val_mae: 45.5732 - val_r2_keras: -3.7133e-01\n",
            "Epoch 22/100\n",
            "75/75 - 17s - loss: 3312.2947 - mae: 46.3216 - r2_keras: -1.7641e-02 - val_loss: 3168.2717 - val_mae: 45.6238 - val_r2_keras: -3.7725e-01\n",
            "Epoch 23/100\n",
            "75/75 - 17s - loss: 3303.6528 - mae: 46.3336 - r2_keras: -2.0042e-02 - val_loss: 3167.9744 - val_mae: 45.6462 - val_r2_keras: -3.7982e-01\n",
            "Epoch 24/100\n",
            "75/75 - 17s - loss: 3296.0918 - mae: 46.2343 - r2_keras: -1.2820e-02 - val_loss: 3167.8835 - val_mae: 45.6597 - val_r2_keras: -3.8142e-01\n",
            "Epoch 25/100\n",
            "75/75 - 17s - loss: 3301.3833 - mae: 46.3643 - r2_keras: -1.5043e-02 - val_loss: 3167.8684 - val_mae: 45.6643 - val_r2_keras: -3.8196e-01\n",
            "Epoch 26/100\n",
            "75/75 - 17s - loss: 3301.6284 - mae: 46.3188 - r2_keras: -1.4246e-02 - val_loss: 3167.8599 - val_mae: 45.6743 - val_r2_keras: -3.8310e-01\n",
            "Epoch 27/100\n",
            "75/75 - 17s - loss: 3304.7297 - mae: 46.3508 - r2_keras: -1.5418e-02 - val_loss: 3167.8691 - val_mae: 45.6805 - val_r2_keras: -3.8375e-01\n",
            "Epoch 28/100\n",
            "75/75 - 17s - loss: 3295.2412 - mae: 46.3211 - r2_keras: -1.5727e-02 - val_loss: 3167.8640 - val_mae: 45.6660 - val_r2_keras: -3.8218e-01\n",
            "Epoch 29/100\n",
            "75/75 - 17s - loss: 3307.6489 - mae: 46.3744 - r2_keras: -1.7468e-02 - val_loss: 3167.8616 - val_mae: 45.6760 - val_r2_keras: -3.8328e-01\n",
            "Epoch 30/100\n",
            "75/75 - 17s - loss: 3270.1394 - mae: 45.4566 - r2_keras: -4.6477e-03 - val_loss: 3016.9136 - val_mae: 44.3918 - val_r2_keras: -3.0453e-01\n",
            "Epoch 31/100\n",
            "75/75 - 17s - loss: 2618.5757 - mae: 37.6235 - r2_keras: 0.1976 - val_loss: 2159.3599 - val_mae: 33.7109 - val_r2_keras: 0.1726\n",
            "Epoch 32/100\n",
            "75/75 - 17s - loss: 2058.0232 - mae: 30.8447 - r2_keras: 0.3685 - val_loss: 1806.2546 - val_mae: 29.2144 - val_r2_keras: 0.3080\n",
            "Epoch 33/100\n",
            "75/75 - 17s - loss: 1826.9025 - mae: 28.2135 - r2_keras: 0.4404 - val_loss: 1709.3276 - val_mae: 26.8482 - val_r2_keras: 0.4198\n",
            "Epoch 34/100\n",
            "75/75 - 17s - loss: 1668.5934 - mae: 26.5508 - r2_keras: 0.4901 - val_loss: 1531.3517 - val_mae: 25.3385 - val_r2_keras: 0.4020\n",
            "Epoch 35/100\n",
            "75/75 - 17s - loss: 1567.8976 - mae: 25.3163 - r2_keras: 0.5222 - val_loss: 1861.7297 - val_mae: 29.3396 - val_r2_keras: 0.3671\n",
            "Epoch 36/100\n",
            "75/75 - 17s - loss: 1434.2747 - mae: 23.9398 - r2_keras: 0.5637 - val_loss: 1197.2727 - val_mae: 20.8915 - val_r2_keras: 0.5932\n",
            "Epoch 37/100\n",
            "75/75 - 17s - loss: 1336.9382 - mae: 22.7943 - r2_keras: 0.5903 - val_loss: 1420.9385 - val_mae: 25.6217 - val_r2_keras: 0.3786\n",
            "Epoch 38/100\n",
            "75/75 - 17s - loss: 1256.1875 - mae: 22.1246 - r2_keras: 0.6164 - val_loss: 1037.6890 - val_mae: 18.9190 - val_r2_keras: 0.6584\n",
            "Epoch 39/100\n",
            "75/75 - 17s - loss: 1174.0117 - mae: 21.2259 - r2_keras: 0.6441 - val_loss: 1110.7341 - val_mae: 20.4644 - val_r2_keras: 0.6382\n",
            "Epoch 40/100\n",
            "75/75 - 17s - loss: 1116.5507 - mae: 20.6634 - r2_keras: 0.6587 - val_loss: 1203.8879 - val_mae: 20.3893 - val_r2_keras: 0.5978\n",
            "Epoch 41/100\n",
            "75/75 - 17s - loss: 1036.8154 - mae: 19.8740 - r2_keras: 0.6846 - val_loss: 1091.6525 - val_mae: 21.1851 - val_r2_keras: 0.6303\n",
            "Epoch 42/100\n",
            "75/75 - 17s - loss: 1008.5830 - mae: 19.7511 - r2_keras: 0.6922 - val_loss: 914.7365 - val_mae: 17.4651 - val_r2_keras: 0.6920\n",
            "Epoch 43/100\n",
            "75/75 - 17s - loss: 942.4658 - mae: 19.1028 - r2_keras: 0.7127 - val_loss: 880.1899 - val_mae: 19.3395 - val_r2_keras: 0.6540\n",
            "Epoch 44/100\n",
            "75/75 - 17s - loss: 911.8405 - mae: 18.8032 - r2_keras: 0.7219 - val_loss: 1095.9607 - val_mae: 17.9639 - val_r2_keras: 0.6401\n",
            "Epoch 45/100\n",
            "75/75 - 17s - loss: 874.5616 - mae: 18.4154 - r2_keras: 0.7342 - val_loss: 919.0855 - val_mae: 21.5818 - val_r2_keras: 0.6253\n",
            "Epoch 46/100\n",
            "75/75 - 17s - loss: 850.8455 - mae: 18.1478 - r2_keras: 0.7401 - val_loss: 819.6644 - val_mae: 19.3563 - val_r2_keras: 0.6488\n",
            "Epoch 47/100\n",
            "75/75 - 17s - loss: 806.8193 - mae: 17.7721 - r2_keras: 0.7521 - val_loss: 761.5006 - val_mae: 18.2261 - val_r2_keras: 0.6976\n",
            "Epoch 48/100\n",
            "75/75 - 17s - loss: 784.0441 - mae: 17.5692 - r2_keras: 0.7615 - val_loss: 874.1310 - val_mae: 20.6066 - val_r2_keras: 0.5919\n",
            "Epoch 49/100\n",
            "75/75 - 17s - loss: 766.6477 - mae: 17.4375 - r2_keras: 0.7663 - val_loss: 870.7070 - val_mae: 18.2501 - val_r2_keras: 0.6423\n",
            "Epoch 50/100\n",
            "75/75 - 17s - loss: 731.3499 - mae: 16.9981 - r2_keras: 0.7772 - val_loss: 744.3980 - val_mae: 16.2333 - val_r2_keras: 0.7210\n",
            "Epoch 51/100\n",
            "75/75 - 17s - loss: 730.3364 - mae: 17.0663 - r2_keras: 0.7766 - val_loss: 1243.0457 - val_mae: 19.9496 - val_r2_keras: 0.5582\n",
            "Epoch 52/100\n",
            "75/75 - 17s - loss: 715.6818 - mae: 16.8882 - r2_keras: 0.7807 - val_loss: 897.6707 - val_mae: 21.1640 - val_r2_keras: 0.5437\n",
            "Epoch 53/100\n",
            "75/75 - 17s - loss: 687.5382 - mae: 16.5594 - r2_keras: 0.7901 - val_loss: 756.9605 - val_mae: 18.3235 - val_r2_keras: 0.6552\n",
            "Epoch 54/100\n",
            "75/75 - 17s - loss: 669.1100 - mae: 16.4569 - r2_keras: 0.7954 - val_loss: 887.5038 - val_mae: 18.9457 - val_r2_keras: 0.6903\n",
            "Epoch 55/100\n",
            "75/75 - 17s - loss: 648.3027 - mae: 16.1326 - r2_keras: 0.8015 - val_loss: 1059.4325 - val_mae: 18.5986 - val_r2_keras: 0.6249\n",
            "Epoch 56/100\n",
            "75/75 - 17s - loss: 626.5184 - mae: 15.9768 - r2_keras: 0.8083 - val_loss: 839.5649 - val_mae: 18.7048 - val_r2_keras: 0.6710\n",
            "Epoch 57/100\n",
            "75/75 - 17s - loss: 623.7119 - mae: 15.9487 - r2_keras: 0.8085 - val_loss: 942.1727 - val_mae: 20.1804 - val_r2_keras: 0.5643\n",
            "Epoch 58/100\n",
            "75/75 - 17s - loss: 589.1954 - mae: 15.4336 - r2_keras: 0.8202 - val_loss: 1064.5573 - val_mae: 20.9117 - val_r2_keras: 0.5297\n",
            "Epoch 59/100\n",
            "75/75 - 17s - loss: 598.9008 - mae: 15.5665 - r2_keras: 0.8155 - val_loss: 838.0197 - val_mae: 16.8409 - val_r2_keras: 0.6701\n",
            "Epoch 60/100\n",
            "75/75 - 17s - loss: 571.3712 - mae: 15.1753 - r2_keras: 0.8256 - val_loss: 1248.2899 - val_mae: 23.3107 - val_r2_keras: 0.4312\n",
            "dict_keys(['loss', 'mae', 'r2_keras', 'val_loss', 'val_mae', 'val_r2_keras'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc_Tto9aUIgC",
        "outputId": "4707c73e-83f1-4e52-c2ba-7884c4654413"
      },
      "source": [
        "# training accuracy\n",
        "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
        "print('\\nMAE: {}'.format(scores[1]))\n",
        "print('\\nR^2: {}'.format(scores[2]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 7s 84ms/step - loss: 640.5283 - mae: 15.6778 - r2_keras: 0.7446\n",
            "\n",
            "MAE: 15.677828788757324\n",
            "\n",
            "R^2: 0.74457186460495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ray8485UOna",
        "outputId": "a78a9619-049e-43cd-9fe9-8650430b3984"
      },
      "source": [
        "y_pred = model.predict(seq_array,verbose=1, batch_size=200)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 7s 84ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[168.12236  ],\n",
              "       [168.09058  ],\n",
              "       [168.05678  ],\n",
              "       ...,\n",
              "       [  2.8825603],\n",
              "       [  2.5155747],\n",
              "       [  2.2000222]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47qiE0vcUbT2",
        "outputId": "b6868dd0-c7a3-40a7-d3fc-e680ccd6f8a1"
      },
      "source": [
        "len(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnX7KC99VpKn"
      },
      "source": [
        "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] \n",
        "                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
        "\n",
        "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
        "#print(\"seq_array_test_last\")\n",
        "#print(seq_array_test_last)\n",
        "#print(seq_array_test_last.shape)\n",
        "\n",
        "# Similarly, we pick the labels\n",
        "#print(\"y_mask\")\n",
        "y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]\n",
        "label_array_test_last = test_df.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
        "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0HppqGnV0e1"
      },
      "source": [
        "y_pred_test = estimator.predict(seq_array_test_last)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiPIu0aYV2dW",
        "outputId": "bfdfde91-4c31-474e-e5f5-111056cd5061"
      },
      "source": [
        "y_true_test = label_array_test_last\n",
        "len(y_true_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQMcxb3zWD9o",
        "outputId": "499177c1-b547-403b-aaa9-70d00b7144d8"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "print(\"Mean Squared Error: \", mean_squared_error(y_true_test, y_pred_test))\n",
        "print(\"Mean Absolute Error: \", mean_absolute_error(y_true_test, y_pred_test))\n",
        "print(\"r-squared: \", r2_score(y_true_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Squared Error:  331.30374\n",
            "Mean Absolute Error:  12.980994\n",
            "r-squared:  0.8031900762972854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D1sXU5kYAGT",
        "outputId": "aa3747dc-0430-49f1-a483-f276fe8b5f20"
      },
      "source": [
        "len(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    }
  ]
}